name: Daily Scrape & Dashboard

on:
  push:
    branches:
      - main
  schedule:
    - cron: "0 2 * * *" # 02:00 UTC â‰ˆ 04:00 Tirana
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"

      - name: Install deps
        run: |
          pip install --upgrade pip
          pip install requests beautifulsoup4 pandas matplotlib

      - name: Scrape listings
        run: python scraper.py

      - name: Merge & dedupe data
        shell: bash
        run: |
          python - <<'EOF'
          import pandas as pd, os

          today = pd.read_csv("today_listings.csv")
          if os.path.exists("historical_listings.csv"):
              hist = pd.read_csv("historical_listings.csv")
              combined = pd.concat([hist, today], ignore_index=True)
          else:
              combined = today

          combined.drop_duplicates(subset=["scrape_date","listing_url"], inplace=True)
          combined.to_csv("historical_listings.csv", index=False)
          EOF

      - name: Commit CSVs
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "actions@github.com"
          git add today_listings.csv historical_listings.csv
          git commit -m "chore: update data $(date -u +'%Y-%m-%d')" || echo "No changes"

      - name: Generate Dashboard
        run: python generate_dashboard.py
        env:
          TZ: Europe/Tirane

      - name: Deploy to gh-pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: docs
          publish_branch: gh-pages
